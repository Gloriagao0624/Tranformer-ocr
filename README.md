# Tranformer-ocr

## model architecture:

<img src="art.png" width = 60%  div align=center />

## Heat map of the source attention (encoder memory) score of the first layer of decoder:

<img src="heatmap.png" width = 70%  div align=center />

## The transformer source code from:http://nlp.seas.harvard.edu/2018/04/03/attention.html
